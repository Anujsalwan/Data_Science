{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afd3a2-916d-4fd2-aa46-dcd993a57b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as py \n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696889b-eea0-48ad-b085-687703597095",
   "metadata": {},
   "source": [
    "Q1. Import the attached CSV files (Diamond.csv) and answer the following questions:\n",
    "A.\tCreate 2 dataframes out of this dataframe â€“ 1 with all numerical variables and other with all categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83586f06-84cf-4be4-91c0-8b6c646c3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond=pd.read_csv(\"Diamond (Non-MAC).csv\")\n",
    "diamond.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7751d3-b9e4-417d-995a-d8689f21f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_diamond=diamond.select_dtypes(include=[\"int\",\"float\"])\n",
    "numeric_diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d50520-d852-4a24-bd7d-d90790818a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_diamond=diamond.select_dtypes(include=[\"object\"])\n",
    "categorical_diamond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df9c80-ed54-4db0-aeda-14bafd1582dd",
   "metadata": {},
   "source": [
    "B.\tCalculate the measure of central tendency of numerical variables using Pandas and statistics libraries and check if the calculated values are different between these 2 libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f5eb3-5c69-477f-a26f-b64abc5711e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef711445-9fc5-4948-8308-d43573d744f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numeric_diamond.columns:\n",
    "    if round(numeric_diamond[i].mean(),2)==round(stat.mean(numeric_diamond[i]),2):\n",
    "        print(\"the mean of colomns\",i,\"is same in pandas & stats liabrary\")\n",
    "        print()\n",
    "    else:\n",
    "        print(\"the mean of colomns\",i,\"is not same in pandas & stats liabrary\")\n",
    "        print()\n",
    "    if round(numeric_diamond[i].median(),2)==round(stat.median(numeric_diamond[i]),2):\n",
    "        print(\"the median of colomns\",i,\"is same in pandas & stats liabrary\")\n",
    "        print()\n",
    "    else:\n",
    "        print(\"the median of colomns\",i,\"is not same in pandas & stats liabrary\")\n",
    "        print()\n",
    "    if list(numeric_diamond[i].mode())==[stat.mode(numeric_diamond[i])]:\n",
    "        print(\"the mode of colomns\",i,\"is same in pandas & stats liabrary\")\n",
    "        print()\n",
    "    else:\n",
    "        print(\"the mode of colomns\",i,\"is not same in pandas & stats liabrary\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c51c3-6466-4985-89bc-d2673de81060",
   "metadata": {},
   "source": [
    "C.\tCheck the skewness of all numeric variables. Mention against each variable if its highly skewed/light skewed/ Moderately skwewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc199af9-c2c0-4669-bb90-15c3528acb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Highly_skewed_list=[]\n",
    "Moderately_Skewed_list=[]\n",
    "Lightly_Skewed_List=[]\n",
    "for i in numeric_diamond.columns:\n",
    "    if numeric_diamond[i].skew() > 1:\n",
    "        \n",
    "        Highly_skewed_list.append(i)\n",
    "        \n",
    "    elif numeric_diamond[i].skew()>=0.5:\n",
    "\n",
    "        Moderately_Skewed_list.append(i)\n",
    "       \n",
    "    else:\n",
    "       \n",
    "       Lightly_Skewed_List.append(i)\n",
    "print(\"The Highly skewed Variables are \",Highly_skewed_list)\n",
    "print(\"The Moderately skewed Variables are \",Moderately_Skewed_list)\n",
    "print(\"The Lightly skewed Variables are \",Lightly_Skewed_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab868e-486e-4f24-95f2-23ac207cf88e",
   "metadata": {},
   "source": [
    "D.\tUse the different transformation techniques to convert skewed data found in previous question into normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed149b8-85e3-4e58-b3e3-dbe00aa94023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Highly_skewed_list.extend(Moderately_Skewed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81f73f-7bf6-4be6-bf85-1262f3a5421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox\n",
    "df_non_skewed=pd.DataFrame()\n",
    "\n",
    "for k in Highly_skewed_list:\n",
    "    df_non_skewed[f'{k}_log'] = np.log(numeric_diamond[k]+1)\n",
    "\n",
    "    \n",
    "    df_non_skewed[f'{k}_sqrt'] = np.sqrt(numeric_diamond[k])\n",
    "\n",
    "  \n",
    "    df_non_skewed[f'{k}_reciprocal'] = 1 / numeric_diamond[k]\n",
    "\n",
    "\n",
    "    df_non_skewed[f'{k}_boxcon'], _ = boxcox(numeric_diamond[k] + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac899320-7205-4d25-a348-cf6bed263442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_skewed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de836c6-78b6-430b-9bac-97758210f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Highly_skewed=[]\n",
    "Moderately_Skewed=[]\n",
    "Lightly_Skewed=[]\n",
    "for i in df_non_skewed.columns:\n",
    "    if df_non_skewed[i].skew() > 1:\n",
    "        \n",
    "        Highly_skewed.append(i)\n",
    "        \n",
    "    elif df_non_skewed[i].skew()>=0.5:\n",
    "\n",
    "        Moderately_Skewed.append(i)\n",
    "       \n",
    "    else:\n",
    "       \n",
    "       Lightly_Skewed.append(i)\n",
    "print(\"The Highly skewed Variables are \",Highly_skewed)\n",
    "print(\"The Moderately skewed Variables are \",Moderately_Skewed)\n",
    "print(\"The Lightly skewed Variables are \",Lightly_Skewed)\n",
    "print(\"The Colomns\",numeric_diamond.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21803e78-9c32-4130-b7f2-bb3d9dd1d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### As per Best Method is Boxcon so I am replacing the variables with boxcon\n",
    "\n",
    "for k in Highly_skewed_list:\n",
    "\n",
    "    transformed_data, _ = boxcox(numeric_diamond[k] + 1)\n",
    "    \n",
    "\n",
    "    numeric_diamond[k] = transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e42413a-d128-452e-be3b-6d921e379e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Highly_skewed_list=[]\n",
    "Moderately_Skewed_list=[]\n",
    "Lightly_Skewed_List=[]\n",
    "for i in numeric_diamond.columns:\n",
    "    if numeric_diamond[i].skew() > 1:\n",
    "        \n",
    "        Highly_skewed_list.append(i)\n",
    "        \n",
    "    elif numeric_diamond[i].skew()>=0.5:\n",
    "\n",
    "        Moderately_Skewed_list.append(i)\n",
    "       \n",
    "    else:\n",
    "       \n",
    "       Lightly_Skewed_List.append(i)\n",
    "print(\"The Highly skewed Variables are \",Highly_skewed_list)\n",
    "print(\"The Moderately skewed Variables are \",Moderately_Skewed_list)\n",
    "print(\"The Lightly skewed Variables are \",Lightly_Skewed_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523397a-cac1-47fb-9f5d-d0b21bb6275e",
   "metadata": {},
   "source": [
    "E.\tCreate a user defined function in python to check the outliers using IQR method. Then pass all numeric variables in that function to check outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25bbfc-dc1b-4be5-b4d3-32b75dcc405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    has_outliers = ((df[column] < lower_bound) | (df[column] > upper_bound)).any()\n",
    "\n",
    "    if has_outliers:\n",
    "        print(f\"The variable '{column}' has outliers.\")\n",
    "    else:\n",
    "        print(f\"The variable '{column}' does not have outliers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8faec9-38ab-441b-8a0f-a311a2eef1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_diamond:\n",
    "    check_outliers_iqr(numeric_diamond, col)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390334d9-558d-4285-a0a5-ef86ca71c0a8",
   "metadata": {},
   "source": [
    "F.\tConvert categorical variables into numerical variables using LabelEncoder technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c849b0c-3c8b-4505-a5ea-764bbb11c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31941fd2-01a4-464f-83b3-e446e4053133",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_diamond:\n",
    "    categorical_diamond[col] = le.fit_transform(categorical_diamond[col].fillna('Missing').astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f8794-5006-471e-9853-a063583576ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_diamond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28888729-4d9b-4cf1-a435-a77e65f2fb94",
   "metadata": {},
   "source": [
    "G.\tUse both the feature scaling techniques (standardscaler/min max scaler) on all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f8398-3ad5-4c8b-b046-91ef1e16e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5888b93-78fb-4418-bfeb-664056698eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(numeric_diamond),  \n",
    "    columns=numeric_diamond.columns,        \n",
    "    index=numeric_diamond.index             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355370ae-bce7-439c-9015-6ad6440b9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533493d5-f8df-4821-8f22-aea02a7aca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567a56f-db06-46bb-b5dc-e595dddd0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5142e70a-3ba1-48f5-aa79-6678c03c2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minmax_scaled = pd.DataFrame(\n",
    "    min_max_scaler.fit_transform(numeric_diamond), \n",
    "    columns=numeric_diamond.columns,               \n",
    "    index=numeric_diamond.index                    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3246e-e59c-4545-84d2-f3eb8fab5a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minmax_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e284ba-266c-45dc-a05a-c3af7bd4559e",
   "metadata": {},
   "source": [
    "H.\tCreate the Histogram for all numeric variables and draw the KDE plot on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e10d20-9ff8-49f5-8124-377e69108f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a50b5b-2dcc-43e7-a0da-fd08b60b8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_diamond.columns:\n",
    "  \n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    sns.histplot(\n",
    "        data=numeric_diamond, \n",
    "        x=col, \n",
    "        kde=True, \n",
    "        bins=30, \n",
    "        stat=\"density\",\n",
    "        edgecolor='black', \n",
    "        color='skyblue'    \n",
    "    )\n",
    "    \n",
    "\n",
    "    plt.title(f'Distribution of {col}', fontsize=16)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914b9d4a-9292-4043-881f-4e9eb886c9eb",
   "metadata": {},
   "source": [
    "I.\tCheck the correlation between all the numeric variables using HeatMap and try to draw some conclusion about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bcb616-77fa-4094-8473-6ba52cdbfe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = numeric_diamond.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c1b11-fe5d-4fce-bb97-2a532740f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,              \n",
    "    fmt=\".2f\",               \n",
    "    cmap='coolwarm',         \n",
    "    linewidths=.5,           \n",
    "    linecolor='black',       \n",
    "    cbar_kws={'label': 'Correlation Coefficient'}\n",
    ")\n",
    "\n",
    "plt.title('Correlation Matrix of Numeric Variables', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb55a0f-04f6-435b-8c7a-4214a13f55a1",
   "metadata": {},
   "source": [
    "### Some Consulsions:-\n",
    "\n",
    "1. Extremely High Positive Correlations (Multicollinearity)\n",
    "The variables 'carat,' 'weight,' 'size,' and 'price' are all extremely highly positively correlated with each other (coefficients ranging from $0.95$ to $0.99$).Weight, Size, and Carat: The correlation between these three physical attributes is near-perfect ($\\approx 0.98 - 0.99$). This suggests they are essentially redundant features measuring the same underlying concept (the physical bulk or mass of the diamond). For modeling, keeping only one (e.g., 'carat' or a composite 'size' metric) would likely suffice.Price and Physical Attributes: 'price' shows a very strong positive relationship with 'carat' ($\\approx 0.97$), 'weight' ($\\approx 0.96$), and 'size' ($\\approx 0.95$). This confirms that the size/mass of the diamond is the dominant factor determining its price.\n",
    "\n",
    "2. Weak/No Linear CorrelationMost other variables show very weak linear correlation (coefficients close to $0.0$):'depth' and 'price' ($\\approx 0.00$): The total depth percentage of the diamond has virtually no linear relationship with its price.'depth' and 'carat' ($\\approx 0.03$): Depth is independent of the carat weight.'table' and 'price' ($\\approx 0.17$): The width of the top facet ('table') has a very weak positive impact on the price.\n",
    "\n",
    "3. Moderate Negative Correlation'depth' and 'table' ($\\approx -0.28$): There is a slight negative correlation between a diamond's depth percentage and its table width. This makes sense geometrically, as a shallower diamond (lower depth) often requires a wider table for light performance, and vice versa.\n",
    "\n",
    "Summary for Modeling\n",
    "\n",
    "\n",
    "The data is characterized by significant multicollinearity among the primary physical features ('carat', 'weight', 'size') and the target variable ('price'). In a predictive model, 'carat' alone is a highly effective, singular predictor for 'price.' The features 'depth' and 'table' are largely independent of the other variables and may contribute unique, non-redundant information to a model, despite their weak individual correlation with price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff216530-63b5-43b6-a177-9cba7de0ff33",
   "metadata": {},
   "source": [
    "Q2. Explain Gradient descent in detail. How changing the values of learning rate can impact the convergence in Gradient Descent."
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b16653-57b9-486d-a758-ba72136f4df7",
   "metadata": {},
   "source": [
    "Gradient Descent is an iterative optimization algorithm used to find the set of parameters (weights and biases) for a machine learning model that minimizes the cost (or loss) function. \n",
    "It works by calculating the gradient (the slope) of the cost function with respect to each parameter, which indicates the direction of the steepest ascent. \n",
    "Since the goal is minimization, the algorithm takes small steps in the opposite direction of the gradient. The step size taken in each iteration is controlled by the learning rate.\n",
    "If the learning rate is set too high, the algorithm might overshoot the minimum, causing the cost function to increase or even diverge completely. \n",
    "Conversely, if the learning rate is set too low, the algorithm will take tiny steps, leading to extremely slow convergence and possibly terminating before the minimum is reached due to time or resource constraints. Therefore, choosing an optimal learning rate is crucial for ensuring efficient and accurate convergence to the minimum loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
